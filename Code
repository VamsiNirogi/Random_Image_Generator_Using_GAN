import numpy as np
import torchvision
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import os
from PIL import Image
import matplotlib.pyplot as plt

# Define the GAN architecture
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(100, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, 3 * 64 * 64),  # Output size: 3 channels x 64 x 64 pixels
            nn.Tanh()  # Output image is normalized between -1 and 1
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(3 * 64 * 64, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 1),
            nn.Sigmoid()  # Output a probability indicating the image is real (1) or fake (0)
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)
        return self.model(x)

class GAN(nn.Module):
    def __init__(self):
        super(GAN, self).__init__()
        self.generator = Generator()
        self.discriminator = Discriminator()

# Data preprocessing
class TextImageDataset(Dataset):
    def __init__(self, text_file, image_data_dir, transform=None):
        self.text_file = text_file
        self.image_data_dir = image_data_dir
        self.transform = transform

        with open(text_file, 'r') as f:
            self.text_data = f.readlines()

        # Dynamically determine the range of image paths based on existing files
        self.image_paths = []
        for i in range(len(self.text_data)):
            image_path = os.path.join(image_data_dir, f"image_{i+1:05d}.jpg")
            if os.path.exists(image_path):
                self.image_paths.append(image_path)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        try:
            image = Image.open(image_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image
        except FileNotFoundError:
            print(f"File not found: {image_path}")
            return None

# Define preprocessing transformations
preprocess = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),  # Convert image to PyTorch tensor
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image pixels to the range [-1, 1]
])

# Load dataset
text_file = r"F:\PyCharm\Proj\flower_text.txt"
image_data_dir = r"F:\PyCharm\Proj\102flowers"
dataset = TextImageDataset(text_file, image_data_dir, transform=preprocess)

# Create DataLoader
dataloader = DataLoader(dataset, batch_size=128, shuffle=True)

# Create GAN model
gan = GAN()

# Define hyperparameters
lr = 0.0002
beta1 = 0.8
beta2 = 0.999
num_epochs = 500

# Define loss function and optimizer
criterion = nn.BCELoss()  # Binary cross-entropy loss
optimizer_G = optim.Adam(gan.generator.parameters(), lr=lr, betas=(beta1, beta2))
optimizer_D = optim.Adam(gan.discriminator.parameters(), lr=lr, betas=(beta1, beta2))

# Define lists to store losses
discriminator_losses = []
generator_losses = []

# Training loop
for epoch in range(num_epochs):
    for batch_idx, images in enumerate(dataloader):
        # Train discriminator
        optimizer_D.zero_grad()
        real_labels = torch.ones(images.size(0), 1)
        fake_labels = torch.zeros(images.size(0), 1)

        real_outputs = gan.discriminator(images)
        real_loss = criterion(real_outputs, real_labels)

        noise = torch.randn(images.size(0), 100)
        fake_images = gan.generator(noise)
        fake_outputs = gan.discriminator(fake_images.detach())
        fake_loss = criterion(fake_outputs, fake_labels)

        discriminator_loss = real_loss + fake_loss
        discriminator_loss.backward()
        optimizer_D.step()

        # Train generator
        optimizer_G.zero_grad()
        noise = torch.randn(images.size(0), 100)
        fake_images = gan.generator(noise)
        outputs = gan.discriminator(fake_images)
        generator_loss = criterion(outputs, real_labels)

        generator_loss.backward()
        optimizer_G.step()

        # Store losses
        discriminator_losses.append(discriminator_loss.item())
        generator_losses.append(generator_loss.item())

        # Print progress
        if batch_idx % 100 == 0:
            print(f"Epoch [{epoch}/{num_epochs}], Batch [{batch_idx}/{len(dataloader)}], "
                  f"Discriminator Loss: {discriminator_loss.item()}, Generator Loss: {generator_loss.item()}")

    # Save generated images periodically
    if epoch % 10 == 0:
        torchvision.utils.save_image(fake_images[:64], f"generated_images_epoch_{epoch}.png", normalize=True)

# Plot loss function graph
plt.figure(figsize=(10, 5))
plt.plot(discriminator_losses, label='Discriminator Loss')
plt.plot(generator_losses, label='Generator Loss')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.title('GAN Training Loss')
plt.legend()
plt.show()

# Save the trained GAN model
torch.save(gan.state_dict(), 'gan_model.pth')
